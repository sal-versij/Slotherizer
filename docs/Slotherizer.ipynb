{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f744a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/logo.png)\n",
    "# Slotherizer - quando ti secchi a leggere\n",
    "\n",
    "<small> Logo generato con Dalle mini: https://huggingface.co/spaces/dalle-mini/dalle-mini </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19242e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/too-many-messages-i-welcome-the-pain.jpg)\n",
    "Da oggi il problema è risolto, grazie ai riassunti automatici di Slotherizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1d72a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0b3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Discord è una piattaforma statunitense di VoIP, messaggistica istantanea e distribuzione digitale progettata per la comunicazione tra comunità. Gli utenti possono comunicare in canali testuali presenti in dei server Discord. In ciascun server si possono ritrovare un gran numero di utenti, di conseguenza i canali testuali potrebbero riempirsi di messaggi ed è per non perdere alcuna novità che abbiamo ideato **Slotherizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4118025",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6618e60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](img/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee5aa5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b03f84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tramite la libreria python discord.py abbiamo realizzato un programma che si interfaccia con un bot discord, creato a priori, mettendosi in ascolto di comandi inviati nei canali in cui è stato aggiunto.\n",
    "\n",
    "Quando riceve il comando\n",
    "```\n",
    "!slotherizer <n>\n",
    "```\n",
    "recupera gli ultimi `n` messaggi ed alcune informazioni utili come il **canale** e gli **utente** che hanno scritto i messaggi insieme alle **date** dei singoli messaggi e li inoltra nella pipeline, scrivendoli in un file di log. \n",
    "Successivamente dopo il processamento dei dati riceverà una risposta da Kafka contenente il riassunto dei messaggi da inoltrare nella chat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fd492",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86b3be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Abbiamo utilizzato logstash per fare batch data ingestion. \n",
    "Recuperando i dati dal file su cui discord scrive e inviandoli simultaneamente sia a Kafka che a elasticsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c40637",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Event streaming (flusso andata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ef09e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Abbiamo utilizzato Kafka per gestire il flow dei dati.\n",
    "\n",
    "In una prima fase dirigerà gli eventi di logstash verso Spark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4ba9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stream processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cb3ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Abbiamo utilizzato Spark per modellare i dati in entrata in un formato compatibile con l'API di OpenAI per il riassunto che poi inoltreremo indietro a Kafka.\n",
    "\n",
    "### OpenAI - GPT-3\n",
    "OpenAI è una compagnia che ricerca e sviluppa inteligenze artificiali e mette a disposizione alcuni modelli basati su GPT-3 che riescono a completare un testo in modo sensibile al contesto.\n",
    "\n",
    "Nel nostro caso dando come linea finale **Tl;Dr** completerà l'input con un riassunto dello stesso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9584fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Event streaming (flusso ritorno)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb7fac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Successivamente per riportare sul bot la risposta dell'API abbiamo utilizzato kafka avendo come producer Spark mentre come consumer il bot discord, in modo da poter stampare sulla chat utente il risultato del comando.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e3f51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Spark come producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d1071",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0662fc2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bot discord come consumer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2bed6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e3d442",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70296c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Abbiamo utilizzato lo standard ELK per il recupero, salvataggio e la visualizzazione di dati allo scopo di monitorare il funzionamento del ristema.\n",
    "\n",
    "\n",
    "![DASHBOARD]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4f72b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Credits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d25247",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Dalle mini](https://huggingface.co/spaces/dalle-mini/dalle-mini)\n",
    "- [Discord](https://discordapp.com/)\n",
    "- [Logstash](https://www.elastic.co/it/logstash)\n",
    "- [ElasticSearch](https://www.elastic.co/it/elasticsearch)\n",
    "- [Kibana](https://www.elastic.co/it/kibana)\n",
    "- [Spark](https://spark.apache.org/)\n",
    "- [OpenAI](https://openai.com)\n",
    "- [GPT-3](https://openai.com/blog/gpt3/)\n",
    "\n",
    "## Autori \n",
    "Giulia Meo e Salvatore Luca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f7898",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Un saluto da GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40519c09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ora non dovremo più leggere tutti i messaggi e potremo anche dedicarci un po' di più alla vita sociale\n",
    "![](img/life-is-too-short-to-read-everything.jpg)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
